{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc2sSpThCAY0"
      },
      "source": [
        "# Generating Markdown with `Nougat`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFW1eh1BCAY1",
        "outputId": "4d0af964-c262-4140-f8d7-eec76731ba32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.5/82.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.8/30.8 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m114.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.5/431.5 kB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m117.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m801.6/801.6 kB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -q pymupdf python-Levenshtein nltk datasets transformers torch pillow kaggle nougat-ocr boto3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyK5MsQ8Fx9X"
      },
      "source": [
        "### If on Google Colab:\n",
        "\n",
        "Comment to code below if not on Google Colab. This code brings Kaggle secrets into Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "yRzoidW3F0kz",
        "outputId": "c85f7477-93da-4d17-bcc4-6e87f7baeb02"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-dff2275c-f05d-4a11-984d-c1626637d660\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-dff2275c-f05d-4a11-984d-c1626637d660\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"dulloa6310\",\"key\":\"6d92840966e000c00b675c1fa08ff7c5\"}'}"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# from google.colab import files\n",
        "# files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmfHtpZ6G7Mw"
      },
      "source": [
        "Wait for `kaggle.json` to load..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_t9MA86hGl1J"
      },
      "outputs": [],
      "source": [
        "# !mkdir ~/.kaggle\n",
        "# !mv ./kaggle.json ~/.kaggle\n",
        "# !chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyKa9HlLCAY3"
      },
      "source": [
        "## Accessing Papers\n",
        "\n",
        "In order for the `kaggle` command to work, you need to create a folder called `.kaggle` in the root directory of your machine, generate an api key on kaggle.com (called `kaggle.json`), and place this file in the .kaggle folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHRP3TJGCAY3",
        "outputId": "7338c4b4-62ab-4eb3-8ba7-70dc37dd377a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading arxiv.zip to /content\n",
            "100% 1.26G/1.26G [00:48<00:00, 28.1MB/s]\n",
            "100% 1.26G/1.26G [00:48<00:00, 28.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d Cornell-University/arxiv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mldDKJ2cCAY3"
      },
      "source": [
        "The command:\n",
        "\n",
        "`kaggle datasets download -d Cornell-University/arxiv`\n",
        "\n",
        "downloads a .zip file, which we need to unzip to get the json file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0o4mX8wYCAY3",
        "outputId": "5ddbbc07-0db8-48e6-e22c-c79252c9eac3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  ./arxiv.zip\n",
            "  inflating: arxiv-metadata-oai-snapshot.json  \n"
          ]
        }
      ],
      "source": [
        "!unzip ./arxiv.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khmmjZ6eCAY4"
      },
      "source": [
        "## Processing Arxiv Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoCQY3MMCAY4"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import requests\n",
        "import os\n",
        "\n",
        "\n",
        "def process_json_file(filename):\n",
        "    dictionaries = []\n",
        "    with open(filename, 'r') as file:\n",
        "        for line in file:\n",
        "            try:\n",
        "                data = json.loads(line)\n",
        "                dictionaries.append(data)\n",
        "            except json.JSONDecodeError:\n",
        "                print(f\"Error decoding line: {line}\")  # Handle invalid JSON lines\n",
        "\n",
        "    return dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9SzHqx3CAY4"
      },
      "outputs": [],
      "source": [
        "data = process_json_file('./arxiv-metadata-oai-snapshot.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "qEKEm3imTQBA",
        "outputId": "db504f35-925f-417c-eb64-4c9ff803f7f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<built-in method keys of dict object at 0x107ef7040>\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>categories</th>\n",
              "      <th>doi</th>\n",
              "      <th>update_date</th>\n",
              "      <th>categories_split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0704.0001</td>\n",
              "      <td>hep-ph</td>\n",
              "      <td>10.1103/PhysRevD.76.013009</td>\n",
              "      <td>2008-11-26</td>\n",
              "      <td>[hep-ph]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0704.0002</td>\n",
              "      <td>math.CO cs.CG</td>\n",
              "      <td>None</td>\n",
              "      <td>2008-12-13</td>\n",
              "      <td>[math.CO, cs.CG]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0704.0003</td>\n",
              "      <td>physics.gen-ph</td>\n",
              "      <td>None</td>\n",
              "      <td>2008-01-13</td>\n",
              "      <td>[physics.gen-ph]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0704.0004</td>\n",
              "      <td>math.CO</td>\n",
              "      <td>None</td>\n",
              "      <td>2007-05-23</td>\n",
              "      <td>[math.CO]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0704.0005</td>\n",
              "      <td>math.CA math.FA</td>\n",
              "      <td>None</td>\n",
              "      <td>2013-10-15</td>\n",
              "      <td>[math.CA, math.FA]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id       categories                         doi update_date  \\\n",
              "0  0704.0001           hep-ph  10.1103/PhysRevD.76.013009  2008-11-26   \n",
              "1  0704.0002    math.CO cs.CG                        None  2008-12-13   \n",
              "2  0704.0003   physics.gen-ph                        None  2008-01-13   \n",
              "3  0704.0004          math.CO                        None  2007-05-23   \n",
              "4  0704.0005  math.CA math.FA                        None  2013-10-15   \n",
              "\n",
              "     categories_split  \n",
              "0            [hep-ph]  \n",
              "1    [math.CO, cs.CG]  \n",
              "2    [physics.gen-ph]  \n",
              "3           [math.CO]  \n",
              "4  [math.CA, math.FA]  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "print(data[0].keys)\n",
        "df = pd.DataFrame(data)[['id', 'categories', 'doi', 'update_date']]\n",
        "df['categories_split'] = df['categories'].apply(lambda x: x.split())\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6qXg3d_Lra-"
      },
      "source": [
        "### Filter By Category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "hyJXA9vuyZl-",
        "outputId": "277728f9-55d3-447f-dfdb-eee6cedcb36c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "84174\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>categories</th>\n",
              "      <th>doi</th>\n",
              "      <th>update_date</th>\n",
              "      <th>categories_split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0704.0047</td>\n",
              "      <td>cs.NE cs.AI</td>\n",
              "      <td>None</td>\n",
              "      <td>2009-09-29</td>\n",
              "      <td>[cs.NE, cs.AI]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0704.0050</td>\n",
              "      <td>cs.NE cs.AI</td>\n",
              "      <td>None</td>\n",
              "      <td>2007-05-23</td>\n",
              "      <td>[cs.NE, cs.AI]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>0704.0304</td>\n",
              "      <td>cs.IT cs.AI math.IT q-bio.PE</td>\n",
              "      <td>10.1007/978-3-642-18003-3_10</td>\n",
              "      <td>2013-04-05</td>\n",
              "      <td>[cs.IT, cs.AI, math.IT, q-bio.PE]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>984</th>\n",
              "      <td>0704.0985</td>\n",
              "      <td>cs.NE cs.AI</td>\n",
              "      <td>None</td>\n",
              "      <td>2007-05-23</td>\n",
              "      <td>[cs.NE, cs.AI]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1027</th>\n",
              "      <td>0704.1028</td>\n",
              "      <td>cs.LG cs.AI cs.NE</td>\n",
              "      <td>None</td>\n",
              "      <td>2007-05-23</td>\n",
              "      <td>[cs.LG, cs.AI, cs.NE]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             id                    categories                           doi  \\\n",
              "46    0704.0047                   cs.NE cs.AI                          None   \n",
              "49    0704.0050                   cs.NE cs.AI                          None   \n",
              "303   0704.0304  cs.IT cs.AI math.IT q-bio.PE  10.1007/978-3-642-18003-3_10   \n",
              "984   0704.0985                   cs.NE cs.AI                          None   \n",
              "1027  0704.1028             cs.LG cs.AI cs.NE                          None   \n",
              "\n",
              "     update_date                   categories_split  \n",
              "46    2009-09-29                     [cs.NE, cs.AI]  \n",
              "49    2007-05-23                     [cs.NE, cs.AI]  \n",
              "303   2013-04-05  [cs.IT, cs.AI, math.IT, q-bio.PE]  \n",
              "984   2007-05-23                     [cs.NE, cs.AI]  \n",
              "1027  2007-05-23              [cs.LG, cs.AI, cs.NE]  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wanted_categories = set(['cs.AI','cs.AR','cs.CC','cs.CE','cs.CG','cs.CL','cs.CR','cs.CV',\n",
        "'cs.CY','cs.DB','cs.DC','cs.DL','cs.DM','cs.DS','cs.ET','cs.FL','cs.GL','cs.GR','cs.GT','cs.HC',\n",
        "'cs.IR','cs.IT','cs.LG','cs.LO','cs.MA','cs.MM','cs.MS','cs.NA','cs.NE','cs.NI','cs.OH','cs.OS',\n",
        "'cs.PF','cs.PL','cs.RO','cs.SC','cs.SD','cs.SE','cs.SI','cs.SY'])\n",
        "\n",
        "def filter_categories(row):\n",
        "  has_cs = False\n",
        "  have_categories = row['categories_split']\n",
        "  for category in have_categories:\n",
        "    if category == 'cs.AI':\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "only_cs = df[df.apply(filter_categories, axis=1)]\n",
        "print(len(only_cs))\n",
        "only_cs.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lupk_j35LmkB"
      },
      "source": [
        "### Sort Articles by Date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "id": "10uyIBcnLlu9",
        "outputId": "c1e64302-076d-40ab-8da0-ece327de1227"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "84174\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>categories</th>\n",
              "      <th>doi</th>\n",
              "      <th>update_date</th>\n",
              "      <th>categories_split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1616530</th>\n",
              "      <td>2203.03668</td>\n",
              "      <td>cs.LG cs.AI cs.HC</td>\n",
              "      <td>None</td>\n",
              "      <td>2024-03-15</td>\n",
              "      <td>[cs.LG, cs.AI, cs.HC]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2026327</th>\n",
              "      <td>2403.09209</td>\n",
              "      <td>cs.CR cs.AI cs.LG</td>\n",
              "      <td>None</td>\n",
              "      <td>2024-03-15</td>\n",
              "      <td>[cs.CR, cs.AI, cs.LG]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2026345</th>\n",
              "      <td>2403.09227</td>\n",
              "      <td>cs.RO cs.AI</td>\n",
              "      <td>None</td>\n",
              "      <td>2024-03-15</td>\n",
              "      <td>[cs.RO, cs.AI]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2026350</th>\n",
              "      <td>2403.09232</td>\n",
              "      <td>cs.AI</td>\n",
              "      <td>None</td>\n",
              "      <td>2024-03-15</td>\n",
              "      <td>[cs.AI]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2026367</th>\n",
              "      <td>2403.09249</td>\n",
              "      <td>cs.AI</td>\n",
              "      <td>None</td>\n",
              "      <td>2024-03-15</td>\n",
              "      <td>[cs.AI]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id         categories   doi update_date  \\\n",
              "1616530  2203.03668  cs.LG cs.AI cs.HC  None  2024-03-15   \n",
              "2026327  2403.09209  cs.CR cs.AI cs.LG  None  2024-03-15   \n",
              "2026345  2403.09227        cs.RO cs.AI  None  2024-03-15   \n",
              "2026350  2403.09232              cs.AI  None  2024-03-15   \n",
              "2026367  2403.09249              cs.AI  None  2024-03-15   \n",
              "\n",
              "              categories_split  \n",
              "1616530  [cs.LG, cs.AI, cs.HC]  \n",
              "2026327  [cs.CR, cs.AI, cs.LG]  \n",
              "2026345         [cs.RO, cs.AI]  \n",
              "2026350                [cs.AI]  \n",
              "2026367                [cs.AI]  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def sort_by_update_date(df):\n",
        "  \"\"\"Sorts a pandas DataFrame by the 'update-date' column.\n",
        "\n",
        "  Args:\n",
        "      df: A pandas DataFrame.\n",
        "\n",
        "  Returns:\n",
        "      A new pandas DataFrame sorted by the 'update-date' column.\n",
        "  \"\"\"\n",
        "\n",
        "  # Ensure 'update-date' is treated as a datetime column\n",
        "  df['update_date'] = pd.to_datetime(df['update_date'])\n",
        "\n",
        "  # Sort in place (modifies the original DataFrame)\n",
        "  df.sort_values(by='update_date', inplace=True, ascending = False)\n",
        "\n",
        "  return df\n",
        "\n",
        "sorted = sort_by_update_date(only_cs.copy())\n",
        "print(len(sorted))\n",
        "sorted.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgM1d4gERSxn"
      },
      "source": [
        "### Collect Reference Count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCcby9jyAApk"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def get_citation_count(papers):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "    papers: List of strings of the format \"ARXIV:XXXXX.XXXXX\", where the value after of ARXIV: is the arxiv id. As an example: \"ARXIV:2106.15928\".\n",
        "  \"\"\"\n",
        "  too_many_request = False\n",
        "\n",
        "  result = []\n",
        "  while not too_many_request:\n",
        "    response = requests.post(\n",
        "      'https://api.semanticscholar.org/graph/v1/paper/batch',\n",
        "      params={'fields': 'influentialCitationCount,externalIds,citationCount'},\n",
        "      json={\"ids\": papers}\n",
        "    )\n",
        "\n",
        "    if response.status_code == 200:\n",
        "      data = response.json()\n",
        "\n",
        "      # Handle Arxiv id not found by API\n",
        "      for article in data:\n",
        "        if article is not None:\n",
        "          cite_count = article['citationCount']\n",
        "          inf_cite_count = article['influentialCitationCount']\n",
        "          arxiv_id = article['externalIds']['ArXiv']\n",
        "          result.append({\"citation_count\" : cite_count, \"id\": arxiv_id, \"inf_cite_count\" : inf_cite_count})\n",
        "\n",
        "      return result\n",
        "    elif response.status_code == 429:\n",
        "      too_many_request = True\n",
        "      time.sleep(10)\n",
        "    else:\n",
        "      print(f\"Error: {response.status_code}\")\n",
        "      return []\n",
        "# https://api.semanticscholar.org/api-docs/graph#tag/Paper-Data/operation/post_graph_get_papers, get paper details, 500 at a time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57tfA9dRvATa",
        "outputId": "707b3aa5-e8e8-49fc-ab59-e746f23425e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing slice 1/169\n",
            "Processing slice 2/169\n",
            "Processing slice 3/169\n",
            "Processing slice 4/169\n",
            "Processing slice 5/169\n",
            "Processing slice 6/169\n",
            "Processing slice 7/169\n",
            "Processing slice 8/169\n",
            "Processing slice 9/169\n",
            "Processing slice 10/169\n",
            "Processing slice 11/169\n",
            "Processing slice 12/169\n",
            "Processing slice 13/169\n",
            "Processing slice 14/169\n",
            "Processing slice 15/169\n",
            "Processing slice 16/169\n",
            "Processing slice 17/169\n",
            "Processing slice 18/169\n",
            "Processing slice 19/169\n",
            "Processing slice 20/169\n",
            "Processing slice 21/169\n",
            "Processing slice 22/169\n",
            "Processing slice 23/169\n",
            "Processing slice 24/169\n",
            "Processing slice 25/169\n",
            "Processing slice 26/169\n",
            "Processing slice 27/169\n",
            "Processing slice 28/169\n",
            "Processing slice 29/169\n",
            "Processing slice 30/169\n",
            "Processing slice 31/169\n",
            "Processing slice 32/169\n",
            "Processing slice 33/169\n",
            "Processing slice 34/169\n",
            "Processing slice 35/169\n",
            "Processing slice 36/169\n",
            "Processing slice 37/169\n",
            "Processing slice 38/169\n",
            "Processing slice 39/169\n",
            "Processing slice 40/169\n",
            "Processing slice 41/169\n",
            "Processing slice 42/169\n",
            "Processing slice 43/169\n",
            "Processing slice 44/169\n",
            "Processing slice 45/169\n",
            "Processing slice 46/169\n",
            "Processing slice 47/169\n",
            "Processing slice 48/169\n",
            "Processing slice 49/169\n",
            "Processing slice 50/169\n",
            "Processing slice 51/169\n",
            "Processing slice 52/169\n",
            "Processing slice 53/169\n",
            "Processing slice 54/169\n",
            "Processing slice 55/169\n",
            "Processing slice 56/169\n",
            "Processing slice 57/169\n",
            "Processing slice 58/169\n",
            "Processing slice 59/169\n",
            "Processing slice 60/169\n",
            "Processing slice 61/169\n",
            "Processing slice 62/169\n",
            "Processing slice 63/169\n",
            "Processing slice 64/169\n",
            "Processing slice 65/169\n",
            "Processing slice 66/169\n",
            "Processing slice 67/169\n",
            "Processing slice 68/169\n",
            "Processing slice 69/169\n",
            "Processing slice 70/169\n",
            "Processing slice 71/169\n",
            "Processing slice 72/169\n",
            "Processing slice 73/169\n",
            "Processing slice 74/169\n",
            "Processing slice 75/169\n",
            "Processing slice 76/169\n",
            "Processing slice 77/169\n",
            "Processing slice 78/169\n",
            "Processing slice 79/169\n",
            "Processing slice 80/169\n",
            "Processing slice 81/169\n",
            "Processing slice 82/169\n",
            "Processing slice 83/169\n",
            "Processing slice 84/169\n",
            "Processing slice 85/169\n",
            "Processing slice 86/169\n",
            "Processing slice 87/169\n",
            "Processing slice 88/169\n",
            "Processing slice 89/169\n",
            "Processing slice 90/169\n",
            "Processing slice 91/169\n",
            "Processing slice 92/169\n",
            "Processing slice 93/169\n",
            "Processing slice 94/169\n",
            "Processing slice 95/169\n",
            "Processing slice 96/169\n",
            "Processing slice 97/169\n",
            "Processing slice 98/169\n",
            "Processing slice 99/169\n",
            "Processing slice 100/169\n",
            "Processing slice 101/169\n",
            "Processing slice 102/169\n",
            "Processing slice 103/169\n",
            "Processing slice 104/169\n",
            "Processing slice 105/169\n",
            "Processing slice 106/169\n",
            "Processing slice 107/169\n",
            "Processing slice 108/169\n",
            "Processing slice 109/169\n",
            "Processing slice 110/169\n",
            "Processing slice 111/169\n",
            "Processing slice 112/169\n",
            "Processing slice 113/169\n",
            "Processing slice 114/169\n",
            "Processing slice 115/169\n",
            "Processing slice 116/169\n",
            "Processing slice 117/169\n",
            "Processing slice 118/169\n",
            "Processing slice 119/169\n",
            "Processing slice 120/169\n",
            "Processing slice 121/169\n",
            "Processing slice 122/169\n",
            "Processing slice 123/169\n",
            "Processing slice 124/169\n",
            "Processing slice 125/169\n",
            "Processing slice 126/169\n",
            "Processing slice 127/169\n",
            "Processing slice 128/169\n",
            "Processing slice 129/169\n",
            "Processing slice 130/169\n",
            "Processing slice 131/169\n",
            "Processing slice 132/169\n",
            "Processing slice 133/169\n",
            "Processing slice 134/169\n",
            "Processing slice 135/169\n",
            "Processing slice 136/169\n",
            "Processing slice 137/169\n",
            "Processing slice 138/169\n",
            "Processing slice 139/169\n",
            "Processing slice 140/169\n",
            "Processing slice 141/169\n",
            "Processing slice 142/169\n",
            "Processing slice 143/169\n",
            "Processing slice 144/169\n",
            "Processing slice 145/169\n",
            "Processing slice 146/169\n",
            "Processing slice 147/169\n",
            "Processing slice 148/169\n",
            "Processing slice 149/169\n",
            "Processing slice 150/169\n",
            "Processing slice 151/169\n",
            "Processing slice 152/169\n",
            "Processing slice 153/169\n",
            "Processing slice 154/169\n",
            "Processing slice 155/169\n",
            "Processing slice 156/169\n",
            "Processing slice 157/169\n",
            "Processing slice 158/169\n",
            "Processing slice 159/169\n",
            "Processing slice 160/169\n",
            "Processing slice 161/169\n",
            "Processing slice 162/169\n",
            "Processing slice 163/169\n",
            "Processing slice 164/169\n",
            "Processing slice 165/169\n",
            "Processing slice 166/169\n",
            "Processing slice 167/169\n",
            "Processing slice 168/169\n",
            "Processing slice 169/169\n",
            "83809\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>citation_count</th>\n",
              "      <th>id</th>\n",
              "      <th>inf_cite_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>53219</th>\n",
              "      <td>18144</td>\n",
              "      <td>2010.11929</td>\n",
              "      <td>3017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71978</th>\n",
              "      <td>14320</td>\n",
              "      <td>1710.10903</td>\n",
              "      <td>2748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81207</th>\n",
              "      <td>20644</td>\n",
              "      <td>1106.1813</td>\n",
              "      <td>2367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73483</th>\n",
              "      <td>9359</td>\n",
              "      <td>1703.03400</td>\n",
              "      <td>2199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75888</th>\n",
              "      <td>16830</td>\n",
              "      <td>1605.08695</td>\n",
              "      <td>1915</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       citation_count          id  inf_cite_count\n",
              "53219           18144  2010.11929            3017\n",
              "71978           14320  1710.10903            2748\n",
              "81207           20644   1106.1813            2367\n",
              "73483            9359  1703.03400            2199\n",
              "75888           16830  1605.08695            1915"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "SLICE_SIZE = 500\n",
        "\n",
        "slices = len(sorted) // SLICE_SIZE\n",
        "if len(sorted) % SLICE_SIZE != 0:\n",
        "  slices += 1\n",
        "\n",
        "all_papers = []\n",
        "for i in range(slices):\n",
        "  print(f\"Processing slice {i + 1}/{slices}\")\n",
        "  start = i * SLICE_SIZE\n",
        "  end = (i + 1) * SLICE_SIZE\n",
        "  formatted_ids = list(sorted.iloc[start:end]['id'].apply(lambda x : f\"ARXIV:{x}\"))\n",
        "\n",
        "  result = get_citation_count(formatted_ids)\n",
        "  all_papers.extend(result)\n",
        "\n",
        "all_papers = pd.DataFrame(all_papers)\n",
        "all_papers = all_papers.sort_values('inf_cite_count', ascending = False)\n",
        "all_papers.to_csv(\"all_papers.csv\", index = False)\n",
        "\n",
        "print(len(all_papers))\n",
        "all_papers.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxyR8CV7az2A"
      },
      "source": [
        "## Downloading PDFs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's remove PDFs that we've already converted to markdown before we download"
      ],
      "metadata": {
        "id": "UrREQOGGvFQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import boto3\n",
        "\n",
        "def only_id(filename):\n",
        "  return filename.split('/')[-1].split('.')[0]\n",
        "\n",
        "def files_with_prefix(bucket_name, prefix):\n",
        "    client = boto3.client(\n",
        "        's3',\n",
        "        aws_access_key_id=userdata.get(\"aws_access_key_id\"),\n",
        "        aws_secret_access_key=userdata.get(\"aws_secret_access_key\"),\n",
        "    )\n",
        "    response = client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
        "\n",
        "    files = set()\n",
        "    if 'Contents' in response:\n",
        "        for obj in response['Contents']:\n",
        "            files.add(only_id(obj['Key']))\n",
        "    return files\n",
        "\n",
        "files = files_with_prefix('arthasai', 'arxiv_markdown/')\n",
        "print(f\"Files in bucket: {files}\")\n",
        "\n",
        "all_papers = all_papers[~all_papers['id'].isin(files)]"
      ],
      "metadata": {
        "id": "vuh55DFvwImz",
        "outputId": "7634e7c8-1ec8-4065-a2eb-93e20911ae65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in bucket: {'', 'user123-paperABC-2024-03-23 20:21:17', 'user123-paperABC-2024-03-24 18:34:43', 'user123-paperABC-2024-03-23 20:46:40', 'user123-paperABC-2024-03-23 19:43:36', 'user123-paperABC-2024-03-23 18:41:33', 'user123-paperABC-2024-03-23 18:47:06', 'user123-paperABC-2024-03-24 17:16:57', 'user123-paperABC-2024-03-24 17:44:59', 'user123-paperABC-2024-03-24 17:57:55', 'user123-paperABC-2024-03-23 17:47:11', 'user123-paperABC-2024-03-24 18:27:37', 'user123-paperABC-2024-03-23 20:57:28', 'user123-paperABC-2024-03-23 20:26:50', 'user123-paperABC-2024-03-23 20:29:31', 'user123-paperABC-2024-03-24 18:03:38', 'user123-paperABC-2024-03-24 17:12:10', 'user123-paperABC-2024-03-24 18:16:41', 'user123-paperABC-2024-03-23 18:40:59', 'user123-paperABC-2024-03-23 22:38:35', 'user123-paperABC-20240318224811-context', 'user123-paperABC-2024-03-24 17:38:30', 'user123-paperABC-2024-03-23 18:20:59', 'user123-paperABC-2024-03-24 17:57:08', 'user123-paperABC-2024-03-24 23:39:38', 'user123-paperABC-2024-03-24 17:39:45', 'user123-paperABC-2024-03-24 18:25:25', 'user123-paperABC-2024-03-24 18:15:07', 'user123-paperABC-20240318224923-context', 'user123-paperABC-2024-03-23 21:42:39', 'user123-paperABC-2024-03-21 20:23:18', 'user123-paperABC-2024-03-24 17:40:13', 'user123-paperABC-2024-03-24 18:25:00', 'user123-paperABC-2024-03-23 17:28:22', 'user123-paperABC-2024-03-24 17:45:59', 'user123-paperABC-20240318231037-context', 'user123-paperABC-2024-03-21 22:54:34', 'user123-paperABC-2024-03-23 17:54:10', 'user123-paperABC-2024-03-23 17:23:57', 'user123-paperABC-2024-03-23 19:53:54', 'user123-paperABC-2024-03-23 22:31:49', 'user123-paperABC-2024-03-23 23:04:24', 'user123-paperABC-20240318224900-context', 'user123-paperABC-2024-03-23 20:24:55', 'user123-paperABC-20240318224148-context', 'user123-paperABC-2024-03-23 18:21:56', 'user123-paperABC-2024-03-23 19:49:45', 'user123-paperABC-2024-03-23 18:08:51', 'user123-paperABC-2024-03-23 22:38:20', 'user123-paperABC-2024-03-24 18:24:27', 'user123-paperABC-2024-03-21 20:32:23', 'user123-paperABC-2024-03-24 17:40:50', 'user123-paperABC-2024-03-24 23:36:48', 'user123-paperABC-20240318231000-context', 'user123-paperABC-2024-03-23 18:07:17', 'user123-paperABC-2024-03-23 20:58:54', 'user123-paperABC-2024-03-23 22:36:20', 'user123-paperABC-2024-03-23 17:26:52', 'user123-paperABC-2024-03-24 17:42:46', 'user123-paperABC-2024-03-24 17:52:54', 'user123-paperABC-2024-03-23 18:20:34', 'user123-paperABC-2024-03-24 17:35:19', 'user123-paperABC-20240318224220-context', 'user123-paperABC-2024-03-21 22:55:39', 'user123-paperABC-2024-03-23 18:00:19', 'user123-paperABC-2024-03-21 20:45:33', 'user123-paperABC-2024-03-24 17:43:01', 'user123-paperABC-20240321154943-context', 'user123-paperABC-2024-03-24 17:18:03', 'user123-paperABC-2024-03-23 17:56:44', 'user123-paperABC-2024-03-23 20:19:43', 'user123-paperABC-2024-03-23 17:48:29', 'user123-paperABC-20240321154703-context', 'user123-paperABC-20240319204634-context', 'user123-paperABC-2024-03-21 20:23:02', 'user123-paperABC-2024-03-23 20:32:25', 'user123-paperABC-2024-03-23 17:33:30', 'user123-paperABC-2024-03-23 20:09:52', 'user123-paperABC-2024-03-23 18:49:58', 'user123-paperABC-20240318224116-context', 'user123-paperABC-20240318223905-context', 'user123-paperABC-2024-03-23 22:37:49', 'user123-paperABC-2024-03-24 17:53:27', 'user123-paperABC-2024-03-23 20:04:48', 'user123-paperABC-2024-03-24 23:40:03', 'user123-paperABC-2024-03-23 22:27:51', 'user123-paperABC-2024-03-24 17:43:17', 'user123-paperABC-2024-03-24 18:13:27', 'user123-paperABC-2024-03-21 20:32:43', 'user123-paperABC-2024-03-23 20:27:13', 'user123-paperABC-2024-03-23 17:37:29', 'user123-paperABC-2024-03-23 20:45:27', 'user123-paperABC-2024-03-24 18:22:31', 'user123-paperABC-2024-03-24 18:28:56', 'user123-paperABC-2024-03-24 17:54:05', 'user123-paperABC-2024-03-24 17:18:22', 'user123-paperABC-2024-03-23 21:02:48', 'user123-paperABC-2024-03-21 20:58:48', 'user123-paperABC-2024-03-23 19:46:10', 'user123-paperABC-2024-03-24 18:18:46', 'user123-paperABC-2024-03-23 19:49:05', 'user123-paperABC-2024-03-23 20:06:50', 'test_user-test_paper-embeddings', 'user123-paperABC-2024-03-23 18:08:15', 'user123-paperABC-20240318203241-context', 'user123-paperABC-2024-03-23 19:08:00', 'user123-paperABC-2024-03-24 17:24:17', 'user123-paperABC-2024-03-23 22:09:12', 'user123-paperABC-20240318232836-context', 'user123-paperABC-2024-03-24 17:50:09', 'user123-paperABC-2024-03-21 20:04:27', 'user123-paperABC-2024-03-23 21:19:13', 'user123-paperABC-2024-03-23 21:42:12', 'user123-paperABC-2024-03-24 18:29:27', 'user123-paperABC-2024-03-24 17:49:32', 'user123-paperABC-2024-03-24 17:22:49', 'user123-paperABC-2024-03-24 18:27:20', 'user123-paperABC-2024-03-23 20:38:29', 'user123-paperABC-2024-03-23 17:53:00', 'user123-paperABC-2024-03-23 20:11:58', 'user123-paperABC-2024-03-24 17:40:40', 'user123-paperABC-2024-03-23 21:39:18'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSMxGmO5vATa",
        "outputId": "5aae26e5-75a9-419a-936f-54da7066e8d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PDF downloaded successfully as 'papers/2010.11929.pdf'\n",
            "PDF downloaded successfully as 'papers/1710.10903.pdf'\n",
            "PDF downloaded successfully as 'papers/1106.1813.pdf'\n",
            "PDF downloaded successfully as 'papers/1703.03400.pdf'\n",
            "PDF downloaded successfully as 'papers/1605.08695.pdf'\n",
            "PDF downloaded successfully as 'papers/1610.02391.pdf'\n",
            "PDF downloaded successfully as 'papers/1705.07874.pdf'\n",
            "PDF downloaded successfully as 'papers/1602.04938.pdf'\n",
            "PDF downloaded successfully as 'papers/1801.01290.pdf'\n",
            "PDF downloaded successfully as 'papers/1502.01852.pdf'\n",
            "PDF downloaded successfully as 'papers/1405.4053.pdf'\n",
            "PDF downloaded successfully as 'papers/1411.1784.pdf'\n",
            "PDF downloaded successfully as 'papers/1512.03012.pdf'\n",
            "PDF downloaded successfully as 'papers/1612.00796.pdf'\n",
            "PDF downloaded successfully as 'papers/1909.11942.pdf'\n",
            "PDF downloaded successfully as 'papers/1806.07366.pdf'\n",
            "PDF downloaded successfully as 'papers/1802.09477.pdf'\n",
            "PDF downloaded successfully as 'papers/1602.07360.pdf'\n",
            "PDF downloaded successfully as 'papers/2203.02155.pdf'\n",
            "PDF downloaded successfully as 'papers/1703.06103.pdf'\n",
            "PDF downloaded successfully as 'papers/1706.02275.pdf'\n",
            "PDF downloaded successfully as 'papers/1210.5644.pdf'\n",
            "PDF downloaded successfully as 'papers/1711.03938.pdf'\n",
            "PDF downloaded successfully as 'papers/1602.07332.pdf'\n",
            "PDF downloaded successfully as 'papers/1605.08803.pdf'\n",
            "PDF downloaded successfully as 'papers/1611.01578.pdf'\n",
            "PDF downloaded successfully as 'papers/2106.09685.pdf'\n",
            "PDF downloaded successfully as 'papers/1803.01271.pdf'\n",
            "PDF downloaded successfully as 'papers/1606.06357.pdf'\n",
            "PDF downloaded successfully as 'papers/2105.05233.pdf'\n",
            "PDF downloaded successfully as 'papers/2307.09288.pdf'\n",
            "PDF downloaded successfully as 'papers/1606.01540.pdf'\n",
            "PDF downloaded successfully as 'papers/1606.03476.pdf'\n",
            "PDF downloaded successfully as 'papers/1612.00837.pdf'\n",
            "PDF downloaded successfully as 'papers/2303.08774.pdf'\n",
            "PDF downloaded successfully as 'papers/2106.07447.pdf'\n",
            "PDF downloaded successfully as 'papers/2201.11903.pdf'\n",
            "PDF downloaded successfully as 'papers/1807.03039.pdf'\n",
            "PDF downloaded successfully as 'papers/1903.07291.pdf'\n",
            "PDF downloaded successfully as 'papers/1506.03340.pdf'\n",
            "PDF downloaded successfully as 'papers/1803.03635.pdf'\n",
            "PDF downloaded successfully as 'papers/1812.05905.pdf'\n",
            "PDF downloaded successfully as 'papers/1503.00075.pdf'\n",
            "PDF downloaded successfully as 'papers/1207.4708.pdf'\n",
            "PDF downloaded successfully as 'papers/1907.02893.pdf'\n",
            "PDF downloaded successfully as 'papers/1609.08144.pdf'\n",
            "PDF downloaded successfully as 'papers/9605103.pdf'\n",
            "PDF downloaded successfully as 'papers/1802.00420.pdf'\n",
            "PDF downloaded successfully as 'papers/1011.0686.pdf'\n",
            "PDF downloaded successfully as 'papers/1604.07379.pdf'\n",
            "PDF downloaded successfully as 'papers/1106.4561.pdf'\n",
            "PDF downloaded successfully as 'papers/1802.01548.pdf'\n",
            "PDF downloaded successfully as 'papers/1706.07269.pdf'\n",
            "PDF downloaded successfully as 'papers/1905.02249.pdf'\n",
            "PDF downloaded successfully as 'papers/0102027.pdf'\n",
            "PDF downloaded successfully as 'papers/2304.02643.pdf'\n",
            "PDF downloaded successfully as 'papers/1003.0146.pdf'\n",
            "PDF downloaded successfully as 'papers/1707.01495.pdf'\n",
            "PDF downloaded successfully as 'papers/1706.08840.pdf'\n",
            "PDF downloaded successfully as 'papers/0805.2368.pdf'\n",
            "PDF downloaded successfully as 'papers/1511.05493.pdf'\n",
            "PDF downloaded successfully as 'papers/1302.4964.pdf'\n",
            "PDF downloaded successfully as 'papers/1609.07843.pdf'\n",
            "PDF downloaded successfully as 'papers/1302.6815.pdf'\n",
            "PDF downloaded successfully as 'papers/2012.07436.pdf'\n",
            "PDF downloaded successfully as 'papers/1206.7051.pdf'\n",
            "PDF downloaded successfully as 'papers/1703.00848.pdf'\n",
            "PDF downloaded successfully as 'papers/1612.00563.pdf'\n",
            "PDF downloaded successfully as 'papers/1607.06520.pdf'\n",
            "PDF downloaded successfully as 'papers/1610.08401.pdf'\n",
            "PDF downloaded successfully as 'papers/1703.04730.pdf'\n",
            "PDF downloaded successfully as 'papers/1901.07031.pdf'\n",
            "PDF downloaded successfully as 'papers/1708.06519.pdf'\n",
            "PDF downloaded successfully as 'papers/2302.05543.pdf'\n",
            "PDF downloaded successfully as 'papers/1109.6051.pdf'\n",
            "PDF downloaded successfully as 'papers/1810.12894.pdf'\n",
            "PDF downloaded successfully as 'papers/1710.02298.pdf'\n",
            "PDF downloaded successfully as 'papers/2105.01601.pdf'\n",
            "PDF downloaded successfully as 'papers/1607.01719.pdf'\n",
            "PDF downloaded successfully as 'papers/2304.08485.pdf'\n",
            "PDF downloaded successfully as 'papers/9501101.pdf'\n",
            "PDF downloaded successfully as 'papers/2103.03230.pdf'\n",
            "PDF downloaded successfully as 'papers/1301.2300.pdf'\n",
            "PDF downloaded successfully as 'papers/1705.05363.pdf'\n",
            "PDF downloaded successfully as 'papers/1509.00685.pdf'\n",
            "PDF downloaded successfully as 'papers/1801.07791.pdf'\n",
            "PDF downloaded successfully as 'papers/1812.02900.pdf'\n",
            "PDF downloaded successfully as 'papers/2010.13902.pdf'\n",
            "PDF downloaded successfully as 'papers/1505.05770.pdf'\n",
            "PDF downloaded successfully as 'papers/1811.12231.pdf'\n",
            "PDF downloaded successfully as 'papers/1809.05053.pdf'\n",
            "PDF downloaded successfully as 'papers/1904.12848.pdf'\n",
            "PDF downloaded successfully as 'papers/1612.03242.pdf'\n",
            "PDF downloaded successfully as 'papers/2009.03300.pdf'\n",
            "PDF downloaded successfully as 'papers/2112.01527.pdf'\n",
            "PDF downloaded successfully as 'papers/1609.05473.pdf'\n",
            "PDF downloaded successfully as 'papers/1910.10045.pdf'\n",
            "PDF downloaded successfully as 'papers/1711.00399.pdf'\n",
            "PDF downloaded successfully as 'papers/2002.00269.pdf'\n",
            "PDF downloaded successfully as 'papers/1806.01261.pdf'\n",
            "PDF downloaded successfully as 'papers/1106.0675.pdf'\n",
            "PDF downloaded successfully as 'papers/1904.08755.pdf'\n",
            "PDF downloaded successfully as 'papers/1707.06887.pdf'\n",
            "PDF downloaded successfully as 'papers/1801.07243.pdf'\n",
            "PDF downloaded successfully as 'papers/1905.00537.pdf'\n",
            "PDF downloaded successfully as 'papers/1803.08024.pdf'\n",
            "PDF downloaded successfully as 'papers/1909.10351.pdf'\n",
            "PDF downloaded successfully as 'papers/1711.07280.pdf'\n",
            "PDF downloaded successfully as 'papers/1702.01135.pdf'\n",
            "PDF downloaded successfully as 'papers/1702.08608.pdf'\n",
            "PDF downloaded successfully as 'papers/1803.05407.pdf'\n",
            "PDF downloaded successfully as 'papers/1704.04683.pdf'\n",
            "PDF downloaded successfully as 'papers/1608.07187.pdf'\n",
            "PDF downloaded successfully as 'papers/1703.03864.pdf'\n",
            "PDF downloaded successfully as 'papers/1705.08926.pdf'\n",
            "PDF downloaded successfully as 'papers/2203.11171.pdf'\n",
            "PDF downloaded successfully as 'papers/1610.00081.pdf'\n",
            "PDF downloaded successfully as 'papers/1802.01561.pdf'\n",
            "PDF downloaded successfully as 'papers/1706.03741.pdf'\n",
            "PDF downloaded successfully as 'papers/1709.00103.pdf'\n",
            "PDF downloaded successfully as 'papers/2101.03961.pdf'\n",
            "PDF downloaded successfully as 'papers/1806.03536.pdf'\n",
            "PDF downloaded successfully as 'papers/1902.09630.pdf'\n",
            "PDF downloaded successfully as 'papers/1606.03490.pdf'\n",
            "PDF downloaded successfully as 'papers/2102.09672.pdf'\n",
            "PDF downloaded successfully as 'papers/1811.00937.pdf'\n",
            "PDF downloaded successfully as 'papers/2010.03759.pdf'\n",
            "PDF downloaded successfully as 'papers/2207.12598.pdf'\n",
            "PDF downloaded successfully as 'papers/0202021.pdf'\n",
            "PDF downloaded successfully as 'papers/2112.07945.pdf'\n",
            "PDF downloaded successfully as 'papers/1605.09782.pdf'\n",
            "PDF downloaded successfully as 'papers/1105.5444.pdf'\n",
            "PDF downloaded successfully as 'papers/2107.07651.pdf'\n",
            "PDF downloaded successfully as 'papers/1809.08887.pdf'\n",
            "PDF downloaded successfully as 'papers/1511.05547.pdf'\n",
            "PDF downloaded successfully as 'papers/1604.00449.pdf'\n",
            "PDF downloaded successfully as 'papers/1709.03815.pdf'\n",
            "PDF downloaded successfully as 'papers/1705.08039.pdf'\n",
            "PDF downloaded successfully as 'papers/1507.04808.pdf'\n",
            "PDF downloaded successfully as 'papers/1803.01422.pdf'\n",
            "PDF downloaded successfully as 'papers/2206.00364.pdf'\n",
            "PDF downloaded successfully as 'papers/1805.10123.pdf'\n",
            "PDF downloaded successfully as 'papers/1607.07043.pdf'\n",
            "PDF downloaded successfully as 'papers/2210.08402.pdf'\n",
            "PDF downloaded successfully as 'papers/1611.04558.pdf'\n",
            "PDF downloaded successfully as 'papers/2109.01134.pdf'\n",
            "PDF downloaded successfully as 'papers/1809.05679.pdf'\n",
            "PDF downloaded successfully as 'papers/0412098.pdf'\n",
            "PDF downloaded successfully as 'papers/2107.13586.pdf'\n",
            "PDF downloaded successfully as 'papers/1805.12114.pdf'\n",
            "PDF downloaded successfully as 'papers/2204.14198.pdf'\n",
            "PDF downloaded successfully as 'papers/1606.01847.pdf'\n",
            "PDF downloaded successfully as 'papers/2106.13230.pdf'\n",
            "PDF downloaded successfully as 'papers/1202.2745.pdf'\n",
            "PDF downloaded successfully as 'papers/1712.04143.pdf'\n",
            "PDF downloaded successfully as 'papers/9906002.pdf'\n",
            "PDF downloaded successfully as 'papers/1506.05908.pdf'\n",
            "PDF downloaded successfully as 'papers/1810.02244.pdf'\n",
            "PDF downloaded successfully as 'papers/1611.09940.pdf'\n",
            "PDF downloaded successfully as 'papers/1506.08909.pdf'\n",
            "PDF downloaded successfully as 'papers/1502.08029.pdf'\n",
            "PDF downloaded successfully as 'papers/1803.09473.pdf'\n",
            "PDF downloaded successfully as 'papers/0904.4727.pdf'\n",
            "PDF downloaded successfully as 'papers/2205.11916.pdf'\n",
            "PDF downloaded successfully as 'papers/1611.09830.pdf'\n",
            "PDF downloaded successfully as 'papers/2003.00196.pdf'\n",
            "PDF downloaded successfully as 'papers/1711.09601.pdf'\n",
            "PDF downloaded successfully as 'papers/1602.04621.pdf'\n",
            "PDF downloaded successfully as 'papers/1709.07871.pdf'\n",
            "PDF downloaded successfully as 'papers/1907.11932.pdf'\n",
            "PDF downloaded successfully as 'papers/1301.2294.pdf'\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[79], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mid\u001b[39m:\n\u001b[1;32m     33\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 34\u001b[0m \u001b[43mdownload_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpapers/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfilename\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[79], line 17\u001b[0m, in \u001b[0;36mdownload_pdf\u001b[0;34m(arxiv_id, filename)\u001b[0m\n\u001b[1;32m     14\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()  \u001b[38;5;66;03m# Check for HTTP errors\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Filter out keep-alive chunks\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/Code/ArthasAI/backend/venv/lib/python3.12/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
            "File \u001b[0;32m~/Documents/Code/ArthasAI/backend/venv/lib/python3.12/site-packages/urllib3/response.py:1043\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1043\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1045\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m   1046\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
            "File \u001b[0;32m~/Documents/Code/ArthasAI/backend/venv/lib/python3.12/site-packages/urllib3/response.py:935\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[0;32m--> 935\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "File \u001b[0;32m~/Documents/Code/ArthasAI/backend/venv/lib/python3.12/site-packages/urllib3/response.py:862\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    859\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 862\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
            "File \u001b[0;32m~/Documents/Code/ArthasAI/backend/venv/lib/python3.12/site-packages/urllib3/response.py:845\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    844\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 845\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
            "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:479\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    478\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 479\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
            "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1252\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1250\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1251\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
            "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def download_pdf(arxiv_id, filename=\"paper.pdf\"):\n",
        "    \"\"\"Downloads a PDF from arXiv given its ID.\n",
        "\n",
        "    Args:\n",
        "        arxiv_id (str): The arXiv ID of the paper.\n",
        "        filename (str, optional): The desired filename for the downloaded PDF.\n",
        "                                  Defaults to \"paper.pdf\".\n",
        "    \"\"\"\n",
        "\n",
        "    url = f\"https://arxiv.org/pdf/{arxiv_id}\"\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status()  # Check for HTTP errors\n",
        "\n",
        "        with open(filename, 'wb') as f:\n",
        "            for chunk in response.iter_content(chunk_size=1024):\n",
        "                if chunk:  # Filter out keep-alive chunks\n",
        "                    f.write(chunk)\n",
        "\n",
        "        print(f\"PDF downloaded successfully as '{filename}'\")\n",
        "\n",
        "    except requests.exceptions.HTTPError as err:\n",
        "        print(f\"HTTP Error: {err}\")\n",
        "    except requests.exceptions.RequestException as err:\n",
        "        print(f\"An error occurred: {err}\")\n",
        "\n",
        "!mkdir papers\n",
        "to_download = list(all_papers.iloc[:100]['id']) # Get top 100 papers\n",
        "for id in to_download:\n",
        "    filename = id\n",
        "    if \"/\" in id:\n",
        "        filename = id.split('/')[-1]\n",
        "    download_pdf(id, f\"papers/{filename}.pdf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yTcQESRasSJ"
      },
      "source": [
        "## Running `Nougat`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIVP7kRbCAY4",
        "outputId": "07d38508-723e-46de-f410-ae1c58f5c6b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘papers’: File exists\n",
            "downloading nougat checkpoint version 0.1.0-base to path /root/.cache/torch/hub/nougat-0.1.0-base\n",
            "config.json: 100% 560/560 [00:00<00:00, 3.41Mb/s]\n",
            "pytorch_model.bin: 100% 1.31G/1.31G [00:25<00:00, 55.4Mb/s]\n",
            "special_tokens_map.json: 100% 96.0/96.0 [00:00<00:00, 619kb/s]\n",
            "tokenizer.json: 100% 2.04M/2.04M [00:00<00:00, 15.9Mb/s]\n",
            "tokenizer_config.json: 100% 106/106 [00:00<00:00, 663kb/s]\n",
            "INFO:root:Found 1 files.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/nougat/model.py:437: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  return torch.var(self.values, 1) / self.values.shape[1]\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "INFO:root:Processing file papers/raptor.pdf with 23 pages\n",
            "100% 6/6 [03:00<00:00, 30.01s/it]\n",
            "-> Cannot close object, library is destroyed. This may cause a memory leak!\n"
          ]
        }
      ],
      "source": [
        "!mkdir papers\n",
        "!mkdir markdown\n",
        "\n",
        "!nougat ./papers -o ./markdown -m 0.1.0-base"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Store Markdown in S3"
      ],
      "metadata": {
        "id": "BL80sU4u0WEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def upload_files_to_s3(local_folder, bucket_name, s3_folder):\n",
        "    \"\"\"Uploads all files from a local folder to an S3 bucket.\n",
        "\n",
        "    Args:\n",
        "        local_folder (str): Path to the local folder containing files.\n",
        "        bucket_name (str): Name of the target S3 bucket.\n",
        "        s3_folder (str): Folder path within the S3 bucket where files should be stored.\n",
        "    \"\"\"\n",
        "\n",
        "    s3 = boto3.client('s3', aws_access_key_id=userdata.get(\"aws_access_key_id\"), aws_secret_access_key=userdata.get(\"aws_secret_access_key\"))\n",
        "\n",
        "    for root, _, filenames in os.walk(local_folder):\n",
        "        for filename in filenames:\n",
        "            local_path = os.path.join(root, filename)\n",
        "            relative_path = os.path.relpath(local_path, local_folder)\n",
        "            s3_path = os.path.join(s3_folder, relative_path)\n",
        "\n",
        "            try:\n",
        "                s3.upload_file(local_path, bucket_name, s3_path)\n",
        "                print(f\"Uploaded '{local_path}' to '{s3_path}'\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error uploading '{local_path}': {e}\")\n",
        "\n",
        "# Example usage\n",
        "local_folder = 'markdown/'\n",
        "bucket_name = 'arthasai'\n",
        "s3_folder = 'arxiv_markdown/'\n",
        "\n",
        "upload_files_to_s3(local_folder, bucket_name, s3_folder)"
      ],
      "metadata": {
        "id": "j0PT-akv0X7E",
        "outputId": "f1387e51-cf2e-4b7c-f4ab-ffe69641e532",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploaded 'markdown/0000.0000.md' to 'arxis_markdown/0000.0000.md'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cpBlmi8F1VKI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}